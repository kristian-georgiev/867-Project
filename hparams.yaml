train_new: &DEFAULT
  dataset: quickdraw # omniglot / miniimagenet / quickdraw
  meta_learner: maml # maml / reptile / anil
  model: small_no_batch_norm # model architecture, specified in /models/models.py
  optimizer: adam
  learning_rate: 1e-3
  lr_finetune: 1e-3
  index: 1
  num_epochs: 2
  n_way: 5
  freeze: 2 # used for anil only, number of layers to freeze
  meta_batch_size: 32 # number of tasks in training batch
  k_support: 5 # k shot for support set
  k_query: 15 # k shot for query set
  n_inner_iter: 5 # number of iterations in inner loop
  seed: 121 # random seed
  saving_gradient_steps: true # save gradient steps to get which directions to plot
  loss_plotting: true # whether to plot loss landscape
  plot_progress: true # whether to plot progress during training
  modelpath: ./models # base path to model state_dict
  trajpath: ./models # base path to weights trajectories 
  modelname: modelname.pt
  weightstrajfilename: weights_trajectories.npy # path to numpy array of weight trajectories
  plot_gridsize: 20 # number of points in plot meshgrid
  last_n_traj_points: 2

pretrained:
  <<: *DEFAULT
  dataset: quickdraw
  seed: 121 # random seed
  loss_plotting: true # whether to plot loss landscape
  plot_gridsize: 20 # number of points in plot meshgrid
  last_n_traj_points: 2
