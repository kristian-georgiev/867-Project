default: &DEFAULT
  dataset: omniglot # omniglot / miniimagenet / quickdraw
  meta_learner: maml # maml / reptile / anil
  model: small # model architecture, specified in /models/models.py: small / medium / large / residual
  optimizer: adam
  learning_rate: 1e-3
  num_epochs: 1
  n_way: 5
  freeze: 2 # used for anil only, number of layers to freeze
  meta_batch_size: 32 # number of tasks in training batch
  k_support: 5 # k shot for support set
  k_query: 15 # k shot for query set
  seed: 121 # random seed
  saving_gradient_steps: true # save gradient steps to get which directions to plot
  loss_plotting: false # whether to plot loss landscape
  plot_progress: true # whether to plot progress during training
  modelpath: ./models/modelname.pickle # path to models folder
  
pretrained:
  modelpath: ./models/modelname.pickle # path to model state_dict
  gradientstepspath: ./models/gradientsteps.npy # path to numpy array of gradient steps
  dataset: omniglot
  seed: 121 # random seed
  loss_plotting: false # whether to plot loss landscape
  plot_progress: true # whether to plot progress during training
